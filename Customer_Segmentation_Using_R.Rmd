---
title: "Customer_Segmentation_with_R"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This project explores using K-Means clustering for market segmentation using R. For this project, I am using a dataset of mall customers. The dataset includes the gender, age, annual income, and spending score (rated from 1-100) of each customer. The end goal of the project is to separate the customers into targetable segments of the population.

## Load Libraries and Data

```{r}
library(tidyverse)
library(readr)
library(broom)
data = read_csv('Mall_Customers.csv')
```

## Explore Data

To start, I will look at the head of our data, the summary of the data to look for missing values, and any duplicated rows. The dataset is pre-cleaned, so I expect there will not be much to note here.

```{r}
head(data)
summary(data)
data[duplicated(data), ]
```

As expected, the dataset is pretty clean. The dataframe looks good, and there are no duplicated rows. I'm going to rename two of the variables to make the dataframe a bit neater.

```{r}
names(data)[names(data) == 'Annual Income (k$)'] <- 'Annual_Income'
names(data)[names(data) == 'Spending Score (1-100)'] <- 'Spending_Score'
```

Now I will look at some of the distributions for each of our variables.

Gender:

```{r}
ggplot(data, aes(x = Gender)) + 
  geom_bar(fill = 'salmon1') + 
  labs(title = 'Gender Counts', x = 'Gender', y = 'Count')
```
Age:

```{r}
ggplot(data, aes(x = Age)) +
  geom_bar(fill='lightseagreen') +
  scale_x_binned(n.breaks = 30) +
  labs(title = 'Age Counts', x = 'Age', y = 'Count')
```

```{r}
ggplot(data, aes(x = Age)) +
  geom_density(fill='lightseagreen') + 
  labs(title = 'Age Density Plot', x = 'Age', y = 'Density')
```
Interaction of Age and annual income:

```{r}
ggplot(data, aes(x = Age, y = Annual_Income)) +
  geom_point(color = 'orangered') + 
  labs(title = 'Age by Annual Income', x = 'Age', y = 'Annual Income')
```

Interaction of Age and Spending Score:

```{r}
ggplot(data, aes(x = Age, y = Spending_Score)) +
  geom_point(color = 'orangered') +
  labs(title = 'Age by Spending Score', x = 'Age', y ='Spending Score')
```
Finally, the interaction of Income and Spending Score:

```{r}
ggplot(data, aes(x = Annual_Income, y = Spending_Score, color = Gender)) +
  geom_point() +
  labs(title = 'Annual Income by Spending Score',
       subtitle = 'Grouped by Gender',
       x= 'Annual Income', y = 'Spending Score')
```
To determine the number of clusters for our model, I will use the elbow method. I will plot the variance within groups between 1 and 20 total clusters.

```{r}
tibble(clusters = 1:20) %>% 
  mutate(mod = map(clusters, ~ kmeans(data[,3:5], centers = .x, nstart = 50))) %>%
  mutate(glanced = map(mod, glance)) %>%
  unnest(glanced) %>%
  ggplot(aes(x=clusters, y = tot.withinss/totss)) +
  geom_line()
```

The elbow plot has a noticeable kink between 5 and 6. Looking at the plots from earlier (especially the income vs spending score plot) I'm estimating 5 to be the best number of clusters to use. I will now use K-Means Clustering with 5 clusters to categorize the data.

```{r}
km_5_clusters <- kmeans(data[,3:5], centers = 5, nstart = 50)
km_5_clusters
```

```{r}
glance(km_5_clusters)
```

Now I will plot the clusters on three plots showing the intersections of Annual Income, Spending Score and Age.

```{r}
ggplot(data, aes(x = Spending_Score, y = Annual_Income)) + 
  geom_point(stat = 'identity', aes(color = as.factor(km_5_clusters$cluster))) +
  scale_color_discrete(name=' ',
                       breaks=c('1', '2', '3', '4', '5'),
                       labels=c('Cluster 1', 'Cluster 2', 'Cluster 3', 
                                'Cluster 4', 'Cluster 5')) +
  labs(title = 'Segments of Mall Customers', 
       subtitle = 'Using K-means Clustering',
       x = 'Spending Score', y = 'Annual Income')
```

```{r}
ggplot(data, aes(x = Age, y = Annual_Income)) + 
  geom_point(stat = 'identity', aes(color = as.factor(km_5_clusters$cluster))) +
  scale_color_discrete(name=' ',
                       breaks=c('1', '2', '3', '4', '5'),
                       labels=c('Cluster 1', 'Cluster 2', 'Cluster 3', 
                       'Cluster 4', 'Cluster 5')) +
  labs(title = 'Segments of Mall Customers', 
       subtitle = 'Using K-means Clustering',
       y = 'Annual Income')
```

```{r}
ggplot(data, aes(x = Age, y = Spending_Score)) + 
  geom_point(stat = 'identity', aes(color = as.factor(km_5_clusters$cluster))) +
  scale_color_discrete(name=' ',
                       breaks=c('1', '2', '3', '4', '5'),
                       labels=c('Cluster 1', 'Cluster 2', 'Cluster 3', 
                                'Cluster 4', 'Cluster 5')) +
  labs(title = 'Segments of Mall Customers', 
       subtitle = 'Using K-means Clustering',
       y = 'Spending Score')
```

The clusters are well-formed and mostly distinct, especially on the income vs spending score plot. We seem to have five defined groups: one with high spending and high income, one with high spending and low income, one with low income and high spending, one with low income and low spending, and one with middle scores for the two variables. The only concern with this model is how much larger cluster 2 is than the other clusters (79 of 200 data points).

To compare, I will now run K-Means clustering looking for 6 clusters.

```{r}
km_6_clusters <- kmeans(data[,3:5], centers = 6, nstart = 50)
km_6_clusters
```

```{r}
glance(km_6_clusters)
```

The clusters are a muh more even size now, but let's see how well defined they are.

```{r}
ggplot(data, aes(x = Spending_Score, y = Annual_Income)) + 
  geom_point(stat = 'identity', aes(color = as.factor(km_6_clusters$cluster))) +
  scale_color_discrete(name=' ',
                       breaks=c('1', '2', '3', '4', '5','6'),
                       labels=c('Cluster 1', 'Cluster 2', 'Cluster 3',
                                'Cluster 4', 'Cluster 5', 'Cluster 6')) +
  labs(title = 'Segments of Mall Customers', 
       subtitle = 'Using K-means Clustering',
       x = 'Spending Score', y = 'Annual Income')
```

```{r}
ggplot(data, aes(x = Age, y = Annual_Income)) + 
  geom_point(stat = 'identity', aes(color = as.factor(km_6_clusters$cluster))) +
  scale_color_discrete(name=' ',
                       breaks=c('1', '2', '3', '4', '5','6'),
                       labels=c('Cluster 1', 'Cluster 2', 'Cluster 3', 
                                'Cluster 4', 'Cluster 5', 'Cluster 6')) +
  labs(title = 'Segments of Mall Customers', 
       subtitle = 'Using K-means Clustering',
       y = 'Annual Income')
```

```{r}
ggplot(data, aes(x = Age, y = Spending_Score)) + 
  geom_point(stat = 'identity', aes(color = as.factor(km_6_clusters$cluster))) +
  scale_color_discrete(name=' ',
                       breaks=c('1', '2', '3', '4', '5','6'),
                       labels=c('Cluster 1', 'Cluster 2', 'Cluster 3', 
                                'Cluster 4', 'Cluster 5', 'Cluster 6')) +
  labs(title = 'Segments of Mall Customers', 
       subtitle = 'Using K-means Clustering',
       y = 'Spending Score')
```

There is a considerable amount of overlap now between clusters 1 and 6 on the income vs spending graph, however we are able to draw more meaningful conclusions regarding age. The model using 5 clusters had a much wider set of rages present in most clusters than the model using 6 clusters. Using 6 clusters will allow us to better target the shoppers.